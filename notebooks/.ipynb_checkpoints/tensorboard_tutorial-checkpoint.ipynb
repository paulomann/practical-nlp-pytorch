{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# transforms\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# datasets\n",
    "trainset = torchvision.datasets.FashionMNIST('./data',\n",
    "    download=True,\n",
    "    train=True,\n",
    "    transform=transform)\n",
    "testset = torchvision.datasets.FashionMNIST('./data',\n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform=transform)\n",
    "\n",
    "# dataloaders\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                        shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                        shuffle=False, num_workers=2)\n",
    "\n",
    "# constant for classes\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
    "\n",
    "# helper function to show an image\n",
    "# (used in the `plot_classes_preds` function below)\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter('runs/fashion_mnist_experiment_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "matplotlib_imshow(img_grid, one_channel=True)\n",
    "writer.add_image('four_fashion_mnist_images', img_grid)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 28, 28])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_graph(net, images)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Embeddings\n",
    "\n",
    "This code below plot the fashion mnist embeddings in a 2D/3D space for visualization. the `writer.add_embedding` function accepts `features`, which is a tensor of size `torch.Size([N, D)`, where `N` is the number of examples and `D` is the number of dimensions (the embedding size). The second argument, `metadata`, can be the class labels as `strings`, and optionally we can have `label_img` which is a tensor of size `torch.Size([N, C, H, W])`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n"
     ]
    }
   ],
   "source": [
    "def select_n_random(data, labels, n=100):\n",
    "    '''\n",
    "    Selects n random datapoints and their corresponding labels from a dataset\n",
    "    '''\n",
    "    assert len(data) == len(labels)\n",
    "\n",
    "    perm = torch.randperm(len(data))\n",
    "    return data[perm][:n], labels[perm][:n]\n",
    "\n",
    "# select random images and their target indices\n",
    "images, labels = select_n_random(trainset.data, trainset.targets)\n",
    "\n",
    "# get the class labels for each image\n",
    "class_labels = [classes[lab] for lab in labels]\n",
    "\n",
    "# log embeddings\n",
    "features = images.view(-1, 28 * 28)\n",
    "# writer.add_embedding(features, metadata=class_labels, label_img=images.unsqueeze(1))\n",
    "writer.add_embedding(features, metadata=class_labels)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def images_to_probs(net, images):\n",
    "    '''\n",
    "    Generates predictions and corresponding probabilities from a trained\n",
    "    network and a list of images\n",
    "    '''\n",
    "    output = net(images)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.numpy())\n",
    "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
    "\n",
    "\n",
    "def plot_classes_preds(net, images, labels):\n",
    "    '''\n",
    "    Generates matplotlib Figure using a trained network, along with images\n",
    "    and labels from a batch, that shows the network's top prediction along\n",
    "    with its probability, alongside the actual label, coloring this\n",
    "    information based on whether the prediction was correct or not.\n",
    "    Uses the \"images_to_probs\" function.\n",
    "    '''\n",
    "    preds, probs = images_to_probs(net, images)\n",
    "    # plot the images in the batch, along with predicted and true labels\n",
    "    fig = plt.figure(figsize=(12, 48))\n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
    "        matplotlib_imshow(images[idx], one_channel=True)\n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "            classes[preds[idx]],\n",
    "            probs[idx] * 100.0,\n",
    "            classes[labels[idx]]),\n",
    "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "running_loss = 0.0\n",
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:    # every 1000 mini-batches...\n",
    "\n",
    "            # ...log the running loss\n",
    "            writer.add_scalar('training loss',\n",
    "                            running_loss / 1000,\n",
    "                            epoch * len(trainloader) + i)\n",
    "\n",
    "            # ...log a Matplotlib Figure showing the model's predictions on a\n",
    "            # random mini-batch\n",
    "            writer.add_figure('predictions vs. actuals',\n",
    "                            plot_classes_preds(net, inputs, labels),\n",
    "                            global_step=epoch * len(trainloader) + i)\n",
    "            running_loss = 0.0\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 10])\n"
     ]
    }
   ],
   "source": [
    "# 1. gets the probability predictions in a test_size x num_classes Tensor\n",
    "# 2. gets the preds in a test_size Tensor\n",
    "# takes ~10 seconds to run\n",
    "class_probs = []\n",
    "class_preds = []\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        output = net(images)\n",
    "        class_probs_batch = [F.softmax(el, dim=0) for el in output]\n",
    "        _, class_preds_batch = torch.max(output, 1)\n",
    "\n",
    "        class_probs.append(class_probs_batch)\n",
    "        class_preds.append(class_preds_batch)\n",
    "\n",
    "test_probs = torch.cat([torch.stack(batch) for batch in class_probs])\n",
    "test_preds = torch.cat(class_preds)\n",
    "\n",
    "# helper function\n",
    "def add_pr_curve_tensorboard(class_index, test_probs, test_preds, global_step=0):\n",
    "    '''\n",
    "    Takes in a \"class_index\" from 0 to 9 and plots the corresponding\n",
    "    precision-recall curve\n",
    "    '''\n",
    "    tensorboard_preds = test_preds == class_index\n",
    "    tensorboard_probs = test_probs[:, class_index]\n",
    "\n",
    "    writer.add_pr_curve(classes[class_index],\n",
    "                        tensorboard_preds,\n",
    "                        tensorboard_probs,\n",
    "                        global_step=global_step)\n",
    "    writer.close()\n",
    "\n",
    "for i in range(len(classes)):\n",
    "    add_pr_curve_tensorboard(i, test_probs, test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
